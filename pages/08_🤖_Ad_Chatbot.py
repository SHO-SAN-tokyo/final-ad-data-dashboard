# pages/08_ğŸ¤–_Ad_Chatbot.py
# -*- coding: utf-8 -*-
"""
ğŸ¤– Ad Chatbot
- NOTION_JOINED_AD_DATA ã‚’å‚ç…§ã—ã€è‡ªç„¶è¨€èªã§ã®è³ªå•ã«å›ç­”
- GPT (OpenAI API) ã‚’åˆ©ç”¨ã—ã¦åˆ†æãƒ»ä¼šè©±ã‚’ç”Ÿæˆ
- ç”»åƒURLã¯ inline è¡¨ç¤ºã€å‹•ç”»URLã¯åŸ‹ã‚è¾¼ã¿ or ãƒªãƒ³ã‚¯è¡¨ç¤º
"""

import streamlit as st
from google.cloud import bigquery
import google.auth
from google.auth import impersonated_credentials
import pandas as pd
import openai
import re

# ============ ãƒšãƒ¼ã‚¸è¨­å®š ============
st.set_page_config(page_title="ğŸ¤– Ad Chatbot", layout="wide")
st.title("ğŸ¤– Ad Chatbot")
st.caption("åºƒå‘Šæ•°å€¤ Ã— Notionæƒ…å ±ã‚’è‡ªç„¶è¨€èªã§ä¼šè©±å½¢å¼ã«åˆ†æã—ã¾ã™ã€‚")

# ============ OpenAI è¨­å®š ============
openai.api_key = st.secrets["openai"]["api_key"]

# ============ BQ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç”Ÿæˆï¼ˆImpersonationï¼‰ ============
def get_notion_client():
    base_creds, _ = google.auth.default()
    target_sa = "notion-ad-bq-access@shosan-ad-expertai.iam.gserviceaccount.com"
    impersonated_creds = impersonated_credentials.Credentials(
        source_credentials=base_creds,
        target_principal=target_sa,
        target_scopes=["https://www.googleapis.com/auth/cloud-platform"],
        lifetime=300,
    )
    return bigquery.Client(credentials=impersonated_creds, project="shosan-ad-expertai")

# ============ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ç®¡ç† ============
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ã“ã‚“ã«ã¡ã¯ï¼åºƒå‘Šãƒ‡ãƒ¼ã‚¿ã¨Notionã®æƒ…å ±ã‚’çµ„ã¿åˆã‚ã›ã¦åˆ†æã§ãã¾ã™ã€‚ä½•ã‚’çŸ¥ã‚ŠãŸã„ã§ã™ã‹ï¼Ÿ"}
    ]

user_input = st.chat_input("åºƒå‘Šã®åŠ¹æœã«ã¤ã„ã¦èã„ã¦ã¿ã¾ã—ã‚‡ã†â€¦")
if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})

# ============ è¡¨ç¤º ============
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"], unsafe_allow_html=True)

# ============ BigQuery Helper ============
def query_bigquery(sql: str) -> pd.DataFrame:
    client = get_notion_client()
    return client.query(sql).to_dataframe()

# ============ URL æ¤œå‡º & åŸ‹ã‚è¾¼ã¿è¡¨ç¤º ============
def render_media_from_text(text: str):
    url_pattern = r"(https?://[^\s]+)"
    urls = re.findall(url_pattern, text)

    for url in urls:
        if any(ext in url.lower() for ext in [".jpg", ".jpeg", ".png", ".gif", "googleusercontent"]):
            st.image(url, use_column_width=True)
        elif "youtube.com" in url or "youtu.be" in url or url.lower().endswith(".mp4"):
            try:
                st.video(url)
            except Exception:
                st.markdown(f"[â–¶ å‹•ç”»ã‚’è¦‹ã‚‹]({url})")
        else:
            st.markdown(f"[ãƒªãƒ³ã‚¯]({url})")

# ============ GPT å‘¼ã³å‡ºã— ============
def run_chat(user_message: str):
    df = query_bigquery("""
        SELECT *
        FROM `shosan-ad-expertai.SHOSAN_Notion_Data.NOTION_JOINED_AD_DATA`
        ORDER BY AD_DELIVERY_MONTH DESC
        LIMIT 50
    """)

    system_prompt = """
    ã‚ãªãŸã¯åºƒå‘Šåˆ†æã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
    ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å‚è€ƒã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚
    - æ•°å€¤ã¯DataFrameã‹ã‚‰å–å¾—ã—ã€æ¨æ¸¬ã§ä½œã‚‰ãªã„ã“ã¨
    - ç”»åƒURLãŒå«ã¾ã‚Œã¦ã„ã‚Œã°å›ç­”æ–‡ã«å‡ºã—ã¦ãã ã•ã„
    - å‹•ç”»URLãŒå«ã¾ã‚Œã¦ã„ã‚Œã°å›ç­”æ–‡ã«å‡ºã—ã¦ãã ã•ã„
    """

    data_str = df.head(10).to_csv(index=False)

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"è³ªå•: {user_message}\n\nå‚è€ƒãƒ‡ãƒ¼ã‚¿:\n{data_str}"}
    ]

    response_stream = openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        stream=True
    )

    full_response = ""
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        for chunk in response_stream:
            delta = chunk.choices[0].delta.content or ""
            full_response += delta
            message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)

        # --- URLåŸ‹ã‚è¾¼ã¿è¡¨ç¤º ---
        render_media_from_text(full_response)

    st.session_state.messages.append({"role": "assistant", "content": full_response})

# ============ å…¥åŠ›ãŒã‚ã‚Œã°å‡¦ç† ============
if user_input:
    run_chat(user_input)


















# # 03_ğŸ§ AI_Insight.py - åˆ†æå¼·åŒ–ç‰ˆã€€
# import streamlit as st
# import pandas as pd, numpy as np
# from google.cloud import bigquery
# import openai

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# # ãƒ­ã‚°ã‚¤ãƒ³èªè¨¼
# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# from auth import require_login
# require_login()

# st.markdown("###### ã˜ã‚…ã‚“ã³ã¡ã‚…ã†ã§ã™ã€‚")

# # openai.api_key = st.secrets["openai"]["api_key"]

# # st.set_page_config(page_title="åºƒå‘ŠAIåˆ†æå®¤", layout="wide")
# # st.title("ğŸ§  åºƒå‘ŠAIåˆ†æå®¤")
# # st.subheader("ğŸ” ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ Ã— ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ– Ã— AIã«ã‚ˆã‚‹ã‚¤ãƒ³ã‚µã‚¤ãƒˆ")

# # # BigQueryèªè¨¼ & ãƒ‡ãƒ¼ã‚¿å–å¾—
# # def load_data():
# #     info = dict(st.secrets["connections"]["bigquery"])
# #     info["private_key"] = info["private_key"].replace("\\n", "\n")
# #     client = bigquery.Client.from_service_account_info(info)
# #     df = client.query("""
# #         SELECT * FROM careful-chess-406412.SHOSAN_Ad_Tokyo.Final_Ad_Data
# #     """).to_dataframe()
# #     return df

# # df = load_data()

# # # ãƒ•ã‚£ãƒ«ã‚¿
# # st.markdown("<h5>ğŸ“† ãƒ‡ãƒ¼ã‚¿æœŸé–“ã®ãƒ•ã‚£ãƒ«ã‚¿</h5>", unsafe_allow_html=True)
# # df["Date"] = pd.to_datetime(df["Date"], errors="coerce")
# # dmin, dmax = df["Date"].min().date(), df["Date"].max().date()
# # sel = st.date_input("æœŸé–“ã‚’é¸æŠ", (dmin, dmax), min_value=dmin, max_value=dmax)
# # if isinstance(sel, (list, tuple)) and len(sel) == 2:
# #     s, e = map(pd.to_datetime, sel)
# #     df = df[(df["Date"].dt.date >= s.date()) & (df["Date"].dt.date <= e.date())]

# # # æ•°å€¤å¤‰æ›
# # df["Cost"] = pd.to_numeric(df["Cost"], errors="coerce").fillna(0)
# # df["Clicks"] = pd.to_numeric(df["Clicks"], errors="coerce").fillna(0)
# # df["Impressions"] = pd.to_numeric(df["Impressions"], errors="coerce").fillna(0)
# # df["ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°"] = pd.to_numeric(df["ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°"], errors="coerce").fillna(0)

# # # æœ€æ–°è¡ŒæŠ½å‡º
# # latest_df = (
# #     df.sort_values("Date")
# #       .dropna(subset=["Date"])
# #       .loc[lambda d: d.groupby("CampaignId")["Date"].idxmax()]
# # )

# # # æŒ‡æ¨™è¨ˆç®—
# # latest_df["CTR"] = latest_df["Clicks"] / latest_df["Impressions"].replace(0, np.nan)
# # latest_df["CVR"] = latest_df["ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°"] / latest_df["Clicks"].replace(0, np.nan)
# # latest_df["CPA"] = latest_df["Cost"] / latest_df["ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°"].replace(0, np.nan)
# # latest_df["CPC"] = latest_df["Cost"] / latest_df["Clicks"].replace(0, np.nan)
# # latest_df["CPM"] = latest_df["Cost"] * 1000 / latest_df["Impressions"].replace(0, np.nan)

# # # åˆ†æå¯¾è±¡ã®é …ç›®ï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ + ã‚³ãƒ”ãƒ¼åˆ— + æ•°å€¤åˆ—ï¼‰
# # copied_cols = [
# #     "HeadlineByAdType", "HeadlinePart1ByAdType", "HeadlinePart2ByAdType",
# #     "Description1ByAdType", "Description2ByAdType"
# # ]

# # group_summary = latest_df.groupby("ã‚«ãƒ†ã‚´ãƒª")[["CTR", "CVR", "CPA", "CPC", "CPM"]].mean().sort_values("CVR", ascending=False)

# # # AIã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆé–¢æ•°
# # def generate_ai_comment():
# #     table = group_summary.to_string(float_format=lambda x: f"{x:.2f}")
# #     prompt = f"""
# # ä»¥ä¸‹ã¯åºƒå‘Šã‚«ãƒ†ã‚´ãƒªã”ã¨ã®å¹³å‡åºƒå‘ŠæŒ‡æ¨™ï¼ˆCTR, CVR, CPA, CPC, CPMï¼‰ã§ã™ï¼š

# # {table}

# # ã¾ãŸã€ä»¥ä¸‹ã¯ãã‚Œãã‚Œã®åºƒå‘Šã«å«ã¾ã‚Œã‚‹ãƒ†ã‚­ã‚¹ãƒˆè¦ç´ ï¼ˆã‚³ãƒ”ãƒ¼ï¼‰ã§ã™ï¼š

# # {latest_df[copied_cols].dropna().head(10).to_string(index=False)}

# # ã“ã®æƒ…å ±ã‚’å…ƒã«ã€ä»¥ä¸‹ã®åˆ†æã‚’æ—¥æœ¬èªã§è¡Œã£ã¦ãã ã•ã„ï¼š

# # ## 1. ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®æ•°å€¤å‚¾å‘
# # ã©ã®ã‚«ãƒ†ã‚´ãƒªãŒé«˜ã„æˆæœã‚’å‡ºã—ã¦ãŠã‚Šã€ãã‚Œã¯ãªãœã‹ï¼Ÿ

# # ## 2. ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°ã®å‚¾å‘åˆ†æ
# # ä¸Šä½ã‚«ãƒ†ã‚´ãƒªã«å…±é€šã™ã‚‹ã‚³ãƒ”ãƒ¼è¡¨ç¾ã¯ã‚ã‚‹ã‹ï¼Ÿ

# # ## 3. æ•°å€¤ã«åŸºã¥ãç”»åƒã®ç‰¹å¾´åˆ†æ
# # ç”»åƒãŒæˆæœã«ä¸ãˆã‚‹å½±éŸ¿ã«ã¤ã„ã¦ä»®èª¬ã‚’è¿°ã¹ã‚‹ï¼ˆCVR, CTR, CPC, CPMã®æŒ‡æ¨™ã‹ã‚‰ï¼‰

# # ## 4. æ”¹å–„ã™ã¹ãã‚«ãƒ†ã‚´ãƒªã¨æ”¹å–„ææ¡ˆ
# # CVRã‚„CTRãŒä½ã„ã‚«ãƒ†ã‚´ãƒªã«ã¯ã©ã®ã‚ˆã†ãªæ”¹å–„ç­–ãŒè€ƒãˆã‚‰ã‚Œã‚‹ã‹ï¼Ÿ

# # ## ç·åˆã¾ã¨ã‚
# # å‚¾å‘ã¨æˆ¦ç•¥å…¨ä½“ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
# #     """
# #     response = openai.chat.completions.create(
# #         model="gpt-3.5-turbo",
# #         messages=[{"role": "user", "content": prompt}]
# #     )
# #     return response.choices[0].message.content.strip()

# # # ãƒœã‚¿ãƒ³ã§ç”Ÿæˆ
# # if st.button("ğŸ¤– AIã«åˆ†æã—ã¦ã‚‚ã‚‰ã†"):
# #     with st.spinner("AIãŒåˆ†æä¸­..."):
# #         try:
# #             st.markdown("### ğŸ’¬ AIã‚³ãƒ¡ãƒ³ãƒˆ:")
# #             st.info(generate_ai_comment())
# #         except Exception as e:
# #             st.error("ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
# #             st.exception(e)
