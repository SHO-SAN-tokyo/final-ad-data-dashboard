import streamlit as st
from google.cloud import bigquery
import pandas as pd

def render():
st.title("âš™ï¸ Unitè¨­å®šãƒšãƒ¼ã‚¸")

# BigQuery èªè¨¼
info_dict = dict(st.secrets["connections"]["bigquery"])
info_dict["private_key"] = info_dict["private_key"].replace("\\n", "\n")
client = bigquery.Client.from_service_account_info(info_dict)

# ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±
project_id = "careful-chess-406412"
dataset = "SHOSAN_Ad_Tokyo"
table = "UnitMapping"
full_table = f"{project_id}.{dataset}.{table}"

# æ‹…å½“è€…ä¸€è¦§ã®å–å¾—
@st.cache_data(ttl=60)
def get_unique_tantousha():
    query = f"""
    SELECT DISTINCT `æ‹…å½“è€…`
    FROM `{project_id}.{dataset}.Final_Ad_Data`
    WHERE `æ‹…å½“è€…` IS NOT NULL AND `æ‹…å½“è€…` != ''
    ORDER BY `æ‹…å½“è€…`
    """
    return client.query(query).to_dataframe()

# Unit Mapping ã®å–å¾—
@st.cache_data(ttl=60)
def load_unit_mapping():
    query = f"SELECT * FROM `{full_table}`"
    return client.query(query).to_dataframe()

# æ‹…å½“è€…è¿½åŠ UI
st.markdown("### â• æ‹…å½“è€…ã‚’Unitã«è¿½åŠ ")

try:
    all_tantousha_df = get_unique_tantousha()
    current_df = load_unit_mapping()
    already_assigned = set(current_df["æ‹…å½“è€…"].dropna())
    unassigned_df = all_tantousha_df[~all_tantousha_df["æ‹…å½“è€…"].isin(already_assigned)]

    if unassigned_df.empty:
        st.info("âœ¨ ã™ã¹ã¦ã®æ‹…å½“è€…ãŒUnitã«æŒ¯ã‚Šåˆ†ã‘ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚")
    else:
        selected_person = st.selectbox("ğŸ‘¤ æ‹…å½“è€…ã‚’é¸æŠ", unassigned_df["æ‹…å½“è€…"])
        input_unit = st.text_input("ğŸ·ï¸ å‰²ã‚Šå½“ã¦ã‚‹Unitå")

        if st.button("ï¼‹ ã“ã®æ‹…å½“è€…ã‚’Unitã«è¿½åŠ "):
            if selected_person and input_unit:
                new_row = pd.DataFrame([{"æ‹…å½“è€…": selected_person, "Unit": input_unit}])
                updated_df = pd.concat([current_df, new_row], ignore_index=True)

                try:
                    with st.spinner("ä¿å­˜ä¸­ã§ã™..."):
                        job_config = bigquery.LoadJobConfig(
                            write_disposition="WRITE_TRUNCATE",
                            schema=[
                                bigquery.SchemaField("æ‹…å½“è€…", "STRING"),
                                bigquery.SchemaField("Unit", "STRING"),
                            ]
                        )
                        job = client.load_table_from_dataframe(updated_df, full_table, job_config=job_config)
                        job.result()
                        st.success(f"âœ… {selected_person} ã‚’ Unitã€{input_unit}ã€ã«è¿½åŠ ã—ã¾ã—ãŸï¼")
                        st.cache_data.clear()
                        current_df = load_unit_mapping()
                except Exception as e:
                    st.error(f"âŒ ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            else:
                st.warning("âš ï¸ Unitåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

except Exception as e:
    st.error(f"âŒ æ‹…å½“è€…ä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# ç·¨é›†å¯èƒ½ãªUnitå‰²å½“ä¸€è¦§
st.markdown("---")
st.markdown("### ğŸ“ æ—¢å­˜ã®Unitå‰²å½“ã‚’ç·¨é›†ãƒ»ä¸¦ã¹æ›¿ãˆ")

editable_df = st.data_editor(
    current_df.sort_values(["Unit", "æ‹…å½“è€…"]),
    use_container_width=True,
    num_rows="dynamic",
    key="editable_unit_table"
)

if st.button("ğŸ’¾ ç·¨é›†å†…å®¹ã‚’ä¿å­˜ã™ã‚‹"):
    with st.spinner("ä¿å­˜ä¸­ã§ã™..."):
        try:
            job_config = bigquery.LoadJobConfig(
                write_disposition="WRITE_TRUNCATE",
                schema=[
                    bigquery.SchemaField("æ‹…å½“è€…", "STRING"),
                    bigquery.SchemaField("Unit", "STRING"),
                ]
            )
            job = client.load_table_from_dataframe(editable_df, full_table, job_config=job_config)
            job.result()
            st.success("âœ… ç·¨é›†ã—ãŸå†…å®¹ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
            st.cache_data.clear()
            current_df = load_unit_mapping()
        except Exception as e:
            st.error(f"âŒ ç·¨é›†å†…å®¹ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# Unitã”ã¨ã®ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°è¡¨ç¤ºï¼ˆèª­ã¿å–ã‚Šå°‚ç”¨ï¼‰
st.markdown("---")
st.markdown("### ğŸ§© Unitã”ã¨ã®æ‹…å½“è€…ä¸€è¦§")

grouped = current_df.groupby("Unit")

for unit, group in grouped:
    st.markdown(f"#### ğŸŸ¢ Unit: {unit}")
    st.dataframe(group[["æ‹…å½“è€…"]].reset_index(drop=True), use_container_width=True)
